
# Reviewing ANOVA conventions

```{r include=FALSE}
# bookdown::preview_chapter("01-anova_review.Rmd", "bookdown::html_document2") 
```

This section is the analysis of reviewing ANOVA prevalence and complexity, as well as the prevalence of ANOVA conventions in research articles published in six psychology journals in 2021: 

1. Journal of Experimental Psychology: General, volume 150, issue 1-12 (158 articles)
2. Psychological Science, volume 32, issues 1-12 (168 articles)
3. Journal of Abnormal Psychology (now Journal of Psychopathology and Clinical Science), volume 130, issues 1-8 (76 articles)
4. Journal of Consulting and Clinical Psychology, volume 89, issues 1-12 (86 articles)
5. Journal of Experimental Social Psychology, volumes 92-97 (121 articles)
6. Journal of Personality and Social Psychology, volumes 120 and 121, issues 1-6 (140 articles)

Package loading and general settings:
```{r setup1, message=FALSE}
# load packages
library(tidyverse)
library(vcd)
library(ggpubr)
library(RColorBrewer)

theme_set(papaja::theme_apa())

# set global chunk options, put figures into folder
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE, 
  include = TRUE, tidy = FALSE, archive = FALSE,
  size = "big", fig.width=8, fig.asp=0.7, 
  width = 1800,
  emmeans=list(msg.interaction=FALSE))

source(here::here("R", "func_kappa.R"))

set.seed(2022)
```

<br>
Only load paper IDs and the journals for later use:
```{r}
# article ID and journal
df_publ <- readxl::read_excel(here::here("data", "CodingSheet.xlsx"),
                              sheet="PaperMeta",
                              range="A1:G750") %>%
  transmute(`Paper ID`, journal = `Publication Title`) %>% 
  mutate(journal = factor(journal),
         journal = fct_recode(journal,
                              JEPG="Journal of Experimental Psychology: General",
                              `Psych Sci`="Psychological Science",
                              `J Abn Psych`="Journal of Abnormal Psychology",
                              JCCP="Journal of Consulting and Clinical Psychology",
                              JESP="Journal of Experimental Social Psychology",
                              JPSP="Journal of Personality and Social Psychology"),
         journal = fct_relevel(journal, "JEPG", "Psych Sci", "J Abn Psych", "JCCP", "JESP", "JPSP")) 
```


## Intra-rater consistency

Estimate the intra-rater consistency for the information on whether the study employed ANOVA, experimental designs and the ANOVA prevalence conventions inspected by Y.J. and H.J. separately.

### Research article and ANOVA

Load the data of title pre-screening and research articles:
```{r}
# "Title_Prescreening" Sheet
df_prescreen <- readxl::read_excel(here::here("data", "CodingSheet.xlsx"),
                                   sheet="Title_Prescreening",
                                   range="A1:C750") %>%
  left_join(df_publ, by="Paper ID") %>%
  select(-Title)

# "ResearchPaper" Sheet
df_mainscreen <- readxl::read_excel(here::here("data", "CodingSheet.xlsx"),
                                    sheet="ResearchPaper",
                                    range="A1:L750") %>%
  left_join(df_publ, by="Paper ID") %>%
  select(-Title)
```

<br>
Calculate Cohen's Kappa of "whether it is a research article":
```{r}
# whether it is a research article (unweighted)
df_res_K <- df_mainscreen %>%
  select(`Research article_YJ`, `Research article_HJ`) %>%
  group_by(`Research article_YJ`, `Research article_HJ`) %>%
  summarize(count = n(), .groups = "drop") %>%
  pivot_wider(names_from=`Research article_HJ`, values_from = count, values_fill = 0)

Ka_res <- df_res_K %>%
  select(-`Research article_YJ`) %>%
  as.matrix() %>%
  Kappa()

print(Ka_res, CI=TRUE) # Kappa for research articles
```

<br>
Calculate Cohen's Kappa of "whether ANOVA was used in the research articles":
```{r}
# whether ANOVA was used (unweighted)
df_aov_K <- df_mainscreen %>% 
  filter(`Research article`==1) %>% # only among research articles
  select(`Use ANOVA_YJ`, `Use ANOVA_HJ`) %>% 
  group_by(`Use ANOVA_YJ`, `Use ANOVA_HJ`) %>% 
  summarize(count=n(), .groups="drop") %>% 
  pivot_wider(names_from=`Use ANOVA_HJ`, values_from = count, values_fill = 0) 

Ka_aov <- df_aov_K %>% 
  select(-`Use ANOVA_YJ`) %>% 
  as.matrix() %>% 
  Kappa()

print(Ka_aov, CI=TRUE) # Kappa for using ANOVA
```


### The first 120 articles

When trying to estimate the consistency of analysis information for the first 20 articles in each journal, we realize that we may not identify the same number of (or the same) ANOVAs for each experiment/article. Therefore, we add some **un-preregistered** analysis steps. Specifically, before evaluating the consistency for the ANOVA information, we count the number of ANOVAs identified by both Y.J. *and* H.J., and the number of ANOVAs only identified by Y.J. *or* H.J. We are unable to evaluate this consistency as there is no information on the number of analyses that are not identified as ANOVA by both Y.J. and H.J. Therefore, we will only display the these numbers without calculating Cohen's Kappa. Next, both Y.J. and H.J. re-reviewed these articles and the intra-rater consistency will be performed on the information after matching the numbers of identified ANOVAs for each article.

#### With mismatched numbers of ANOVAs

Load data for analysis information of the first 20 articles in each journal:
```{r}
# read the coding sheet for the first round by YJ (before)
df_conv_YJ1_before <- 
  readxl::read_excel(here::here("data", "CodingSheet_first20.xlsx"),
                     sheet="AnalysisInfo_first20_YJ_before",
                     range="A1:AR205") %>%
  filter(!is.na(`Paper ID`)) %>% 
  select(`Paper ID`, First20, Exp_ID, DV) %>% 
  mutate(rater = "YJ")

# read the coding sheet for the first round by HJ (before)
df_conv_HJ1_before <- 
  readxl::read_excel(here::here("data", "CodingSheet_first20.xlsx"),
                     sheet="AnalysisInfo_first20_HJ_before",
                     range="A1:AR205") %>%
  filter(!is.na(`Paper ID`)) %>% 
  select(`Paper ID`, First20, Exp_ID, DV) %>% 
  mutate(rater = "HJ")
```

<br>
Contrast the number of ANOVAs identified by Y.J. and H.J.:
```{r}
df_conv_before <- bind_rows(df_conv_YJ1_before, df_conv_HJ1_before) %>% 
  group_by(rater, `Paper ID`) %>% 
  summarize(count = n(), .groups = "drop") %>% 
  pivot_wider(names_from = rater, values_from = count, values_fill = 0) %>% 
  mutate(diff = HJ-YJ,
         YJ1_HJ1 = pmin(HJ, YJ),
         YJ0_HJ1 = ifelse(diff>0, diff, 0),
         YJ1_HJ0 = ifelse(diff<0, -diff, 0)) %>% 
  arrange(as.numeric(str_remove(`Paper ID`, "P"))) 

sum_conv_before <- df_conv_before %>% 
  summarize(YJ1_HJ1 = sum(YJ1_HJ1),
            YJ0_HJ1 = sum(YJ0_HJ1),
            YJ1_HJ0 = sum(YJ1_HJ0))
sum_conv_before 
```
where `YJ1_HJ1` denotes the number of ANOVAs identified by both Y.J. and H.J., `YJ0_HJ1` denotes the number of ANOVAs identified by H.J., but not Y.J., `YJ1_HJ0` denotes the number of ANOVAs identified by Y.J., but not H.J.

<br>
It may happen that although both raters identified the same number of ANOVAs for a particular research article, essentially they identified different ANOVAs. For instance, one rater only identified an ANOVA for accuracy but the other rater only identified an ANOVA for response times in the same article. Although the number of ANOVA matched, both raters actually missed one ANOVA. Therefore, we additionally check this case for all articles. The numbers of identified ANOVA after corrections are: 
```{r}
cmatrix_first20_before <- tibble(
  Rating = c("anova_HJ_1", "anova_HJ_0"),
  anova_YJ_1 = c(sum_conv_before$YJ1_HJ1-1, sum_conv_before$YJ1_HJ0+1),
  anova_YJ_0 = c(sum_conv_before$YJ0_HJ1+1, NA),
)
cmatrix_first20_before
```
where `anova_YJ_1` and `anova_YJ_0` denote the number of ANOVAs that are identified and that are not identified by Y.J. `anova_HJ_1` and `anova_HJ_0` denote the number of ANOVAs that are identified and that are not identified by H.J. 

#### After matching the identified ANOVAs in each article 

Load analysis information after matching the identified ANOVAs in each article:
```{r}
# read the coding sheet for the first round by YJ (after)
df_conv_YJ1_after <- 
  readxl::read_excel(here::here("data", "CodingSheet_first20.xlsx"),
                     sheet="AnalysisInfo_first20_YJ_after",
                     range="A1:AR205") %>%
  filter(!is.na(`Paper ID`)) %>% 
  select(-Title) %>% 
  mutate(row_idx = c(2:205))

# read the coding sheet for the first round by HJ (after)
df_conv_HJ1_after <- 
  readxl::read_excel(here::here("data", "CodingSheet_first20.xlsx"),
                     sheet="AnalysisInfo_first20_HJ_after",
                     range="A1:AR205") %>%
  filter(!is.na(`Paper ID`)) %>% 
  select(-Title) %>% 
  mutate(row_idx = c(2:205))
```

##### Experimental designs
Cohen's Kappa for experimental designs:
```{r}
# experimental designs
design_list <- c("N_factor", "max_No_levels")

kappa_ed <- lapply(design_list, 
                  thekappa, # available in R/func_kappa.R
                  df1=df_conv_YJ1_after, 
                  df2=df_conv_HJ1_after, 
                  isweighted=TRUE) %>%
  bind_rows()
kappa_ed
```

<br> Confusion matrix for `N_factor`:
```{r}
as.data.frame(kappa_ed$conf_mat[1])
```

<br> Confusion matrix for `max_No_levels`:
```{r}
as.data.frame(kappa_ed$conf_mat[2])
```

<br> 
##### Convention A
Cohen's Kappa for convention A:
```{r}
# Convention A
con_a_list <- c("a1_report_all", "a3_correction")

kappa_a <- lapply(con_a_list, 
                  thekappa, # available in R/func_kappa.R
                  df1=filter(df_conv_YJ1_after, a2_multiway==1),
                  df2=filter(df_conv_HJ1_after, a2_multiway==1)) %>%
  bind_rows()
kappa_a
```

<br> Confusion matrix for `a1_report_all`:
```{r}
as.data.frame(kappa_a$conf_mat[[1]])
```

<br>
Rows with different information for `a1_report_all`:
```{r}
bind_cols(a1_report_all_YJ = df_conv_YJ1_after$a1_report_all,
          df_conv_HJ1_after) %>%  
  select(a1_report_all_YJ, 
         a1_report_all_HJ = a1_report_all,
         row_idx, `Paper ID`, Exp_ID, DV, a2_multiway, everything()) %>% 
  filter(a1_report_all_YJ != a1_report_all_HJ,
         a2_multiway==1)
```

<br> Confusion matrix for `a3_correction`:
```{r}
as.data.frame(kappa_a$conf_mat[[2]])
```

<br>
##### Convention B
Main effect and post-hoc analysis.

<br>
Cohen's Kappa for convention B:
```{r}
# Convention B
con_b_wlist <- 
  c("b1_N_factor3+", # number of factors with three or more levels
    "b2_N_significant_b1", # number of (reported) significant factors with three or more levels
    "b3_N_non-sig_b1") # number of (reported) non-significant factors with three or more levels

kappa_bw <- lapply(con_b_wlist, 
                   thekappa, # available in R/func_kappa.R
                   isweighted=TRUE,
                   df1=filter(df_conv_YJ1_after, 
                              max_No_levels>2), 
                   df2=filter(df_conv_HJ1_after, 
                              max_No_levels>2)) %>%
  bind_rows()
kappa_bw
```

<br> Confusion matrix for `b1_N_factor3+`:
```{r}
as.data.frame(kappa_bw$conf_mat[[1]])
```

<br> Confusion matrix for `b2_N_significant_b1`:
```{r}
as.data.frame(kappa_bw$conf_mat[[2]])
```

<br>
Rows with different information on `b2_N_significant_b1`:
```{r}
bind_cols(b2_N_significant_b1_YJ = df_conv_YJ1_after$`b2_N_significant_b1`,
          df_conv_HJ1_after) %>%  
  filter(max_No_levels>2) %>% 
  select(b2_N_significant_b1_YJ, 
         b2_N_significant_b1_HJ = `b2_N_significant_b1`,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(b2_N_significant_b1_YJ != b2_N_significant_b1_HJ)
```

<br> Confusion matrix for `b3_N_non-sig_b1`:
```{r}
as.data.frame(kappa_bw$conf_mat[[3]])
```

<br>
Rows with different information on `b3_N_non-sig_b1`:
```{r}
bind_cols(`b3_N_non-sig_b1_YJ` = df_conv_YJ1_after$`b3_N_non-sig_b1`,
          df_conv_HJ1_after) %>%  
  filter(max_No_levels>2) %>% 
  select(`b3_N_non-sig_b1_YJ`, 
         `b3_N_non-sig_b1_HJ` = `b3_N_non-sig_b1`,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(`b3_N_non-sig_b1_YJ` != `b3_N_non-sig_b1_HJ`)
```

<br><br>
Only evaluate consistency of `b7_main_name` using the rows with consistent information in `b1_N_factor3+`, `b2_N_significant_b1`, and `b3_N_non-sig_b1`:
```{r}
tmp_exclude_b1 <- c(186, 187) # rows with inconsistent information
kappa_bu1 <- thekappa(
  df1=filter(df_conv_YJ1_after, 
             max_No_levels>2, 
             !(row_idx %in% tmp_exclude_b1)),
  df2=filter(df_conv_HJ1_after,
             max_No_levels>2,
             !(row_idx %in% tmp_exclude_b1)),
  colname = "b7_main_name") # which factor was checked (1 denotes the only one; NA denotes 'not applicable')

kappa_bu1
```

<br> Confusion matrix for `b7_main_name`:
```{r}
as.data.frame(kappa_bu1$conf_mat[[1]])
```

<br>
Rows with different information on `b7_main_name`:
```{r}
bind_cols(`b7_main_name_YJ` = df_conv_YJ1_after$`b7_main_name`,
          df_conv_HJ1_after) %>%  
  filter(max_No_levels>2,
         !(row_idx %in% tmp_exclude_b1)) %>% 
  select(`b7_main_name_YJ`, 
         `b7_main_name_HJ` = `b7_main_name`,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(`b7_main_name_YJ` != `b7_main_name_HJ`)
```

<br><br>
Only evaluate consistency of `b8_posthoc` using the rows with consistent information in `b1_N_factor3+`, `b2_N_significant_b1`, `b3_N_non-sig_b1`, and `b7_main_name`:
```{r}
tmp_exclude_b2 <- c(186, 187, 199, 200) # rows with inconsistent information
kappa_bu2 <- thekappa(
  df1=filter(df_conv_YJ1_after, 
             max_No_levels>2, 
             b7_main_name != "NA",
             !(row_idx %in% tmp_exclude_b2)),
  df2=filter(df_conv_HJ1_after,
             max_No_levels>2,
             b7_main_name != "NA",
             !(row_idx %in% tmp_exclude_b2)),
  colname = "b8_posthoc") 

kappa_bu2
```

<br> Confusion matrix for `b8_posthoc`:
```{r}
as.data.frame(kappa_bu2$conf_mat[[1]])
```

<br>
Rows with different information on `b8_posthoc`:
```{r}
bind_cols(b8_posthoc_YJ = df_conv_YJ1_after$b8_posthoc,
          df_conv_HJ1_after) %>%  
  filter(max_No_levels>2,
         b7_main_name != "NA",
         !(row_idx %in% tmp_exclude_b2)) %>%
  select(b8_posthoc_YJ, 
         b8_posthoc_HJ = b8_posthoc,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(b8_posthoc_YJ != b8_posthoc_HJ)
```

<br><br>
Only evaluate consistency of `b9_correction` using rows with consistent information in `b1_N_factor3+`, `b2_N_significant_b1`, `b3_N_non-sig_b1`, and performed post-hoc analysis (`b8_posthoc==1`):
```{r}
tmp_exclude_b3 <- c(174, 186, 187, 199, 200) # rows with inconsistent information
kappa_bu3 <- thekappa(
  df1=filter(df_conv_YJ1_after, 
             max_No_levels>2,
             !(row_idx %in% tmp_exclude_b3),
             b8_posthoc==1),
  df2=filter(df_conv_HJ1_after,
             max_No_levels>2,
             !(row_idx %in% tmp_exclude_b3),
             b8_posthoc==1),
  colname = "b9_correction") 

kappa_bu3
```

<br> 
Confusion matrix for `b9_correction`:
```{r}
as.data.frame(kappa_bu3$conf_mat[[1]])
```

<br>
Rows with different information on `b9_correction`:
```{r}
bind_cols(b9_correction_YJ = df_conv_YJ1_after$b9_correction,
          df_conv_HJ1_after) %>%  
  filter(max_No_levels>2,
         !(row_idx %in% tmp_exclude_b3),
         b8_posthoc==1) %>% 
  select(b9_correction_YJ, 
         b9_correction_HJ = b9_correction,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(b9_correction_YJ != b9_correction_HJ)
```

<br><br>
Summary for Convention B:
```{r}
(kappa_b <- bind_rows(kappa_bw, kappa_bu1, kappa_bu2, kappa_bu3))
```

<br>
##### Convention C
Interaction and simple effect analysis

<br>
Cohen's Kappa for convention C:
```{r}
# Convention C
con_c_wlist <- c("c1_N_2way_inter", "c2_N_sig_in_c1", "c3_N_non-sig_in_c1")

kappa_cw <- lapply(con_c_wlist, 
                   thekappa, # available in R/func_kappa.R
                   isweighted=TRUE,
                   df1=filter(df_conv_YJ1_after, N_factor>1),
                   df2=filter(df_conv_HJ1_after, N_factor>1)) %>%
  bind_rows()

kappa_cw
```

<br> 
Confusion matrix for `c1_N_2way_inter`:
```{r}
as.data.frame(kappa_cw$conf_mat[[1]])
```

<br> 
Confusion matrix for `c2_N_sig_in_c1`:
```{r}
as.data.frame(kappa_cw$conf_mat[[2]])
```

<br>
Rows with different information on `c2_N_sig_in_c1`:
```{r}
bind_cols(c2_N_sig_in_c1_YJ = df_conv_YJ1_after$c2_N_sig_in_c1,
          df_conv_HJ1_after) %>%  
  filter(N_factor>1) %>%
  select(c2_N_sig_in_c1_YJ, 
         c2_N_sig_in_c1_HJ = c2_N_sig_in_c1,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(c2_N_sig_in_c1_YJ != c2_N_sig_in_c1_HJ)
```

<br> 
Confusion matrix for `c3_N_non-sig_in_c1`:
```{r}
as.data.frame(kappa_cw$conf_mat[[3]])
```

<br>
Rows with different information on `c3_N_non-sig_in_c1`:
```{r}
bind_cols(`c3_N_non-sig_in_c1_YJ` = df_conv_YJ1_after$`c3_N_non-sig_in_c1`,
          df_conv_HJ1_after) %>%  
  filter(N_factor>1) %>% 
  select(`c3_N_non-sig_in_c1_YJ`, 
         `c3_N_non-sig_in_c1_HJ` = `c3_N_non-sig_in_c1`,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(`c3_N_non-sig_in_c1_YJ` != `c3_N_non-sig_in_c1_HJ`)
```

<br><br>
Only evaluate consistency of `c7_2way_name` using the rows with consistent information in `c1_N_2way_inter`, `c2_N_sig_in_c1`, and `c3_N_non-sig_in_c1`: 
```{r}
kappa_cu1 <- thekappa(df1=filter(df_conv_YJ1_after, 
                                 N_factor>1),
                      df2=filter(df_conv_HJ1_after, 
                                 N_factor>1),
                      colname = "c7_2way_name")
kappa_cu1
```

<br> 
Confusion matrix for `c7_2way_name`:
```{r}
as.data.frame(kappa_cu1$conf_mat[[1]])
```

<br>
Rows with different information on `c7_2way_name`:
```{r}
diff_c7 <- bind_cols(c7_2way_name_YJ = df_conv_YJ1_after$c7_2way_name,
                     df_conv_HJ1_after) %>%  
  filter(N_factor > 1) %>% 
  select(c7_2way_name_YJ, 
         c7_2way_name_HJ = c7_2way_name,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(tolower(c7_2way_name_YJ) != tolower(c7_2way_name_HJ))
diff_c7
```

<br><br>
Only evaluate consistency of `c8_simple_effect` using the rows with consistent information in `c1_N_2way_inter`, `c2_N_sig_in_c1`, `c3_N_non-sig_in_c1`, and checked main effects (`c7_2way_name != "NA"`):
```{r}
tmp_exclude_c2 <- diff_c7$row_idx

kappa_cu2 <- thekappa(
  df1=filter(df_conv_YJ1_after, 
             N_factor>1,
             c7_2way_name != "NA",
             !(row_idx %in% tmp_exclude_c2)),
  df2=filter(df_conv_HJ1_after, 
             N_factor>1,
             c7_2way_name != "NA",
             !(row_idx %in% tmp_exclude_c2)),
  colname = "c8_simple_effect")

kappa_cu2
```

<br> 
Confusion matrix for `c8_simple_effect`:
```{r}
as.data.frame(kappa_cu2$conf_mat[[1]])
```

<br>
Rows with different information on `c8_simple_effect`:
```{r}
diff_c8 <- bind_cols(c8_simple_effect_YJ = df_conv_YJ1_after$c8_simple_effect,
                     df_conv_HJ1_after) %>%  
  filter(N_factor>1,
         c7_2way_name != "NA",
         !(row_idx %in% tmp_exclude_c2)) %>% 
  select(c8_simple_effect_YJ, 
         c8_simple_effect_HJ = c8_simple_effect,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(c8_simple_effect_YJ != c8_simple_effect_HJ)

diff_c8
```

<br><br>
Only evaluate consistency of `c9_correction` using the rows with consistent information in `c1_N_2way_inter`, `c2_N_sig_in_c1`, `c3_N_non-sig_in_c1`, and performed simple effect analysis (`c8_simple_effect==1`):
```{r}
tmp_exclude_c3 <- c(diff_c7$row_idx, diff_c8$row_idx)

kappa_cu3 <- thekappa(
  df1=filter(df_conv_YJ1_after,
             N_factor>1,
             c8_simple_effect==1,
             !(row_idx %in% tmp_exclude_c3)),
  df2=filter(df_conv_HJ1_after, 
             N_factor>1,
             c8_simple_effect==1,
             !(row_idx %in% tmp_exclude_c2)),
  colname = "c9_correction")

kappa_cu3
```

<br> 
Confusion matrix for `c9_correction`:
```{r}
as.data.frame(kappa_cu3$conf_mat[[1]])
```

<br>
Rows with different information on `c9_correction`:
```{r}
bind_cols(c9_correction_YJ = df_conv_YJ1_after$c9_correction,
          df_conv_HJ1_after) %>%  
  filter(N_factor>1,
         c8_simple_effect==1,
         !(row_idx %in% tmp_exclude_c2)) %>% 
  select(c9_correction_YJ, 
         c9_correction_HJ = c9_correction,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(c9_correction_YJ != c9_correction_HJ) 
```

<br><br>
Summary for Convention C:
```{r}
(kappa_c <- bind_rows(kappa_cw, kappa_cu1, kappa_cu2, kappa_cu3))
```

<br>
##### Convention D and E
Separate or collapse factors and perform more ANOVAs depending on the statistical significance of a higher-level interaction.

Cohen's Kappa for the significance of the highest-level interaction:
```{r}
# Convention D & E
kappa_d1e1 <- thekappa(df1=filter(df_conv_YJ1_after, 
                                  N_factor>2),
                       df2=filter(df_conv_HJ1_after, 
                                  N_factor>2),
                       colname="d1_e1_highest_sig")
kappa_d1e1
```

<br> 
Confusion matrix for `d1_e1_highest_sig`:
```{r}
as.data.frame(kappa_d1e1$conf_mat[[1]])
```

<br>
Rows with different information for `d1_e1_highest_sig`:
```{r}
bind_cols(d1_e1_highest_sig_YJ = df_conv_YJ1_after$d1_e1_highest_sig,
          df_conv_HJ1_after) %>%  
  filter(N_factor > 2) %>% 
  select(d1_e1_highest_sig_YJ, 
         d1_e1_highest_sig_HJ = d1_e1_highest_sig,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(d1_e1_highest_sig_YJ != d1_e1_highest_sig_HJ)
```

Cohen's Kappa for Convention D and E:
```{r}
# separate one factor (for significant higher-level interaction)
kappa_d <- thekappa(df1=filter(df_conv_YJ1_after, 
                               N_factor>2, 
                               d1_e1_highest_sig==1,
                               !(row_idx %in% 135)),
                    df2=filter(df_conv_HJ1_after, 
                               N_factor>2, 
                               d1_e1_highest_sig==1,
                               !(row_idx %in% 135)),
                    colname="d1_separate")

# combine/collapse one factor (for non-significant higher-level interaction)
kappa_e <- thekappa(df1=filter(df_conv_YJ1_after, 
                               N_factor>2, 
                               d1_e1_highest_sig==0,
                               !(row_idx %in% 135)),
                    df2=filter(df_conv_HJ1_after, 
                               N_factor>2, 
                               d1_e1_highest_sig==0,
                               !(row_idx %in% 135)),
                    colname="e1_combine")

bind_rows(kappa_d, kappa_e)
```

<br> 
Confusion matrix for `d1_separate`:
```{r}
as.data.frame(kappa_d$conf_mat[[1]])
```

<br> 
Confusion matrix for `e1_combine`:
```{r}
as.data.frame(kappa_e$conf_mat[[1]])
```

<br>
Rows with different information for `e1_combine`:
```{r}
bind_cols(e1_combine_YJ = df_conv_YJ1_after$e1_combine,
          df_conv_HJ1_after) %>%  
  filter(N_factor > 2,
         d1_e1_highest_sig==0,
         !(row_idx %in% 135)) %>% 
  select(e1_combine_YJ, 
         e1_combine_HJ = e1_combine,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(e1_combine_YJ != e1_combine_HJ)
```

<br><br>
Summary for Convnetion D and E:
```{r}
(kappa_de <- bind_rows(kappa_d1e1, kappa_d, kappa_e))
```


##### Other information

Cohen's Kappa for simple interaction analysis:
```{r}
kappa_o1 <- thekappa(df1=df_conv_YJ1_after,
                     df2=df_conv_HJ1_after,
                     colname="Simple interaction analysis (appliable?)")

kappa_o2 <- thekappa(df1=filter(df_conv_YJ1_after, 
                                `Simple interaction analysis (appliable?)`==1),
                     df2=filter(df_conv_HJ1_after, 
                                `Simple interaction analysis (appliable?)`==1),
                     colname="Simple interaction analysis (applied?)")

bind_rows(kappa_o1, kappa_o2)
```

<br> 
Confusion matrix for `Simple interaction analysis (appliable?)`:
```{r}
as.data.frame(kappa_o1$conf_mat[[1]])
```

<br> 
Confusion matrix for `Simple interaction analysis (applied?)`:
```{r}
as.data.frame(kappa_o2$conf_mat[[1]])
```

<br>
Rows with different information for `Simple interaction analysis (applied?)` when it is applicable:
```{r}
bind_cols(applied_YJ = df_conv_YJ1_after$`Simple interaction analysis (applied?)`,
          df_conv_HJ1_after) %>%  
  filter(`Simple interaction analysis (appliable?)`==1) %>% 
  select(applied_YJ, 
         applied_HJ = `Simple interaction analysis (applied?)`,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(applied_YJ != applied_HJ)
```

Cohen's Kappa for pre-registration information:
```{r}
olist <- c("Pre-registration", 
           "Registered reports")

kappa_o3 <- lapply(olist, 
                  thekappa, # available in R/func_kappa.R
                  df1=df_conv_YJ1_after,
                  df2=df_conv_HJ1_after) %>%
  bind_rows()

kappa_o3
```

<br> 
Confusion matrix for `Pre-registration`:
```{r}
as.data.frame(kappa_o3$conf_mat[[1]])
```

<br>
Rows with different information for `Pre-registration`:
```{r}
bind_cols(`Pre-registration_YJ` = df_conv_YJ1_after$`Pre-registration`,
          df_conv_HJ1_after) %>%  
  select(`Pre-registration_YJ`, 
         `Pre-registration_HJ` = `Pre-registration`,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(`Pre-registration_YJ` != `Pre-registration_HJ`)
```

<br> 
Confusion matrix for `Registered reports`:
```{r}
as.data.frame(kappa_o3$conf_mat[[2]])
```

Rows with different information for `Registered reports`:
```{r}
bind_cols(`Registered reports_YJ` = df_conv_YJ1_after$`Registered reports`,
          df_conv_HJ1_after) %>%  
  select(`Registered reports_YJ`, 
         `Registered reports_HJ` = `Registered reports`,
         row_idx, `Paper ID`, Exp_ID, DV, Design, everything()) %>% 
  filter(`Registered reports_YJ` != `Registered reports_HJ`)
```

<br><br>
Summary for other information:
```{r}
(kappa_o <- bind_rows(kappa_o1, kappa_o2, kappa_o3))
```

##### Summary consistency for ANOVA conventions
```{r}
(kappa_df <- bind_rows(kappa_ed, kappa_a, kappa_b, kappa_c, kappa_de, kappa_o))
```
Descriptive statistics of the consistency:
```{r}
# the mean consistency
tibble(mean = mean(kappa_df$value),
       min = min(kappa_df$value),
       max = max(kappa_df$value))
```

```{r save the kappa_df to supplementary}
# save consistency results to display in supplementary materials
saveRDS(kappa_df, file=file.path("supplementary", "kappa_df"))
```


## Prevalence of ANOVA and the conventions

Load analysis information of all reviewed ANOVAs:
```{r}
# read the coding sheet for the first round (after resolving inconsistency) and
# that for the rest articles
df_conv <- bind_rows(
  readxl::read_excel(here::here("data", "CodingSheet_first20.xlsx"),
                     sheet="AnalysisInfo_first20",
                     range="A1:AR205") %>% 
    mutate(c6_inter_sig = as.character(c6_inter_sig)), 
  readxl::read_excel(here::here("data", "CodingSheet.xlsx"),
                     sheet="AnalysisInfo_1",
                     range="A1:AR504"),
  readxl::read_excel(here::here("data", "CodingSheet.xlsx"),
                     sheet="AnalysisInfo_2",
                     range="A1:AR964")) %>%
  select(-c(Title, First20)) %>% 
  left_join(df_publ, by="Paper ID") %>% 
  mutate(`Paper ID` = as_factor(`Paper ID`),
         use_ANOVA = as.integer(use_ANOVA),
         included = as.integer(included),
         N_factor = as.integer(N_factor),
         max_No_levels = as.integer(max_No_levels),
         a1_report_all = as.integer(a1_report_all),
         a2_multiway = as.integer(a2_multiway),
         a3_correction = as_factor(a3_correction),
         `b1_N_factor3+` = as.integer(`b1_N_factor3+`),
         b2_N_significant_b1 = as.integer(b2_N_significant_b1),
         `b3_N_non-sig_b1` = as.integer(`b3_N_non-sig_b1`),
         b4_which_sig_main = as.integer(b4_which_sig_main),
         b5_which_nonsig_main = as.integer(b5_which_nonsig_main),
         b6_main_effect_sig = as.integer(b6_main_effect_sig),
         b8_posthoc = as.integer(b8_posthoc),
         b9_correction = as_factor(b9_correction),
         b9_correction = fct_relevel(b9_correction, "NA", "none"),
         c1_N_2way_inter = as.integer(c1_N_2way_inter),
         c2_N_sig_in_c1 = as.integer(c2_N_sig_in_c1),
         `c3_N_non-sig_in_c1` = as.integer(`c3_N_non-sig_in_c1`),
         c4_which_sig_inter = as.integer(c4_which_sig_inter),
         c5_which_nonsig_inter = as.integer(c5_which_nonsig_inter),
         c8_simple_effect = as.integer(c8_simple_effect),
         c9_correction = as_factor(c9_correction),
         c9_correction = fct_relevel(c9_correction, "NA", "none"),
         d1_e1_highest_sig = as.integer(d1_e1_highest_sig),
         d1_separate = as.integer(d1_separate),
         e1_combine = as.integer(e1_combine),
         `Simple interaction analysis (appliable?)` = as.integer(`Simple interaction analysis (appliable?)`),
         `Simple interaction analysis (applied?)` = as.integer(`Simple interaction analysis (applied?)`),
         `Pre-registration` = as.integer(`Pre-registration`),
         `Registered reports` = as.integer(`Registered reports`),
         Framework = as_factor(Framework))

head(df_conv)
```

The number of (unique) paper ID in analysis information coding sheet is `r nlevels(df_conv[["Paper ID"]])`, which matches the number of ANOVAs identified in the screening (see below).

### Screening information

Articles included at each stage:
```{r}
# number of articles included at each stage
df_included_all <- df_mainscreen %>%  
  summarize(journal = "Overall",
            In1_all = n(), # total number of articles
            In2_title = sum(1-Title_Prescreening), # number of articles remaining after title pre-screening
            In3_research = sum(`Research article`), # number of identified research article
            In4_ANOVA = sum(`Use ANOVA`), # number of articles used ANOVAs
            In5_include = sum(Included)) # finally included ANOVAs

# number of articles at different stages
df_included <- df_mainscreen %>% 
  group_by(journal) %>% 
  summarize(In1_all = n(),
            In2_title = sum(1-Title_Prescreening),
            In3_research = sum(`Research article`),
            In4_ANOVA = sum(`Use ANOVA`),
            In5_include = sum(Included)) %>% 
  add_row(df_included_all, .before=1)
df_included
```
`In1_all` denotes the number of all articles;  
`In2_title` denotes the number of articles after title pre-screening;  
`In3_research` denotes the number of research articles;  
`In4_ANOVA` denotes the number of research articles used ANOVAs;  
`In5_include` denotes the number of research articles included in following reviewing.  

<br>
The percentage of included articles:
```{r}
# Percentage (relative to the total number of articles)
df_included %>% 
  transmute(journal, In1_all,
            In2_title = paste0(round((In2_title/In1_all)*100, 2), '%'),
            In3_research = paste0(round((In3_research/In1_all)*100, 2), '%'),
            In4_ANOVA = paste0(round((In4_ANOVA/In1_all)*100, 2), '%'),
            In5_include = paste0(round((In5_include/In1_all)*100, 2), '%'))
```

<br>
The number of excluded articles at each stage:
```{r}
# number of articles excluded at different stages
df_excluded <- df_mainscreen %>% 
  group_by(journal) %>% 
  summarize(Ex1_all = n(),
            Ex2_title = sum(Title_Prescreening),
            Ex3_research = sum(1-`Research article`),
            Ex4_ANOVA = sum(1-`Use ANOVA`),
            Ex5_exclude = sum(1-Included)) %>% 
  add_row( # add summary row
    summarize(df_mainscreen, 
              journal = "Overall",
              Ex1_all = n(),
              Ex2_title = sum(Title_Prescreening),
              Ex3_research = sum(1-`Research article`),
              Ex4_ANOVA = sum(1-`Use ANOVA`),
              Ex5_exclude = sum(1-Included)),
    .before=1)
df_excluded
```

### ANOVA prevalence
The prevalence of ANOVAs:
```{r}
# The percentage of articles employing ANOVA among all research articles:  
df_prevalence <- df_included %>% 
  mutate(prevalence_anova = paste0(round(In4_ANOVA/In3_research*100, 2), '%'))
df_prevalence
```
Please note that `prevalence_anova` is calculated by `In4_ANOVA/In3_research`.

### ANOVA complexity

```{r}
df_complex <- df_conv %>%
  filter(included==1) %>%
  transmute(`Paper ID`, 
            Design_int = str_split(Design, "_"),
            Design = sapply(Design_int, function(x){paste(sort(as.numeric(x), decreasing=T), collapse="_")}),
            N_factor, max_No_levels, 
            # N_factor = sapply(Design_int, function(x){length(as.numeric(x))}),
            # Max_level = sapply(Design_int, function(x){max(as.numeric(x))}),
            Avg_No_levels = sapply(Design_int, function(x){mean(as.numeric(x))}), # per factor
            Complexity = sapply(Design_int, function(x){prod(as.numeric(x))}),
            journal)
```

Across ANOVAs:
```{r}
df_complexity <- df_complex %>%
  group_by(journal) %>%
  summarize(mean_N_factor = mean(N_factor),
            mean_max_N_levels = mean(max_No_levels),
            mean_complexity = mean(Complexity)) %>%
  add_row( # add summary row
    summarize(df_complex,
              journal = "Overall",
              mean_N_factor = mean(N_factor),
              mean_max_N_levels = mean(max_No_levels),
              mean_complexity = mean(Complexity)),
    .before = 1)
df_complexity
```

```{r save the anova prevalence and complexity to supplementary}
# save prevalence and complexity results to display in supplementary materials
df_pre_com <- left_join(df_prevalence, df_complexity, by="journal") %>% 
  transmute(Journal=journal,
            N = as.integer(In1_all),
            `N title` = as.integer(In2_title),
            `N research` = as.integer(In3_research),
            `N ANOVAs` = as.integer(In4_ANOVA),
            Prevalence = prevalence_anova,
            `N factors` = mean_N_factor,
            `N conditions` = mean_complexity)

saveRDS(df_pre_com, file=file.path("supplementary", "aov_pre_com.rds"))
df_pre_com
```

```{r fig.width=10, fig.asp=.6, warning=FALSE}
for (iN in 1:4) {
  
  tmpplot <- df_complex %>%
    filter(N_factor == iN) %>% 
    mutate(design_ = str_replace_all(Design, '_', '*')) %>%
    ggplot(aes(x = reorder(design_, Complexity))) +
    geom_histogram(stat="count") +
    scale_y_continuous(expand = c(0, 0)) +
    # facet_wrap(vars(N_factor), scales = "free", ncol=2) +
    labs(x = "Experimental designs") 
  
  if (iN!=1){
    tmpplot <- tmpplot +
      theme(axis.text.x = element_text(angle = 45, hjust=.75))
  }
  
  assign(paste0("plot_design", iN), tmpplot)
}

plot_design12 <- ggarrange(plot_design1, plot_design2,
                         widths = c(3, 7))
plot_design34 <- ggarrange(plot_design3, plot_design4,
                         widths = c(7, 3))
plot_design <- ggarrange(plot_design12, plot_design34, 
                         nrow=2, heights = c(1, 1.1))
plot_design
```

#### Alluvial figure 
Information used to created the Alluvial figure at https://sankeymatic.com/build/ to display the ANOVA complexity.
```{r}
# frequency of factor numbers
df_complex %>% 
  group_by(N_factor) %>% 
  summarize(count = n())
```

```{r}
# frequency of each design
df_complex %>%
  select(N_factor, Design) %>%
  group_by(N_factor, Design) %>%
  summarize(count = n(), .groups="drop") %>% 
  arrange(N_factor, desc(count))
```

```{r}
# Frequency of each "complexity" (i.e., the total number of levels)
df_complex %>%
  select(Design, Complexity) %>%
  group_by(Complexity, Design) %>%
  summarize(count = n(), .groups="drop")
```

```{r}
knitr::include_graphics(file.path("figures", "anova_complexity_2400_1400.png"))
```


### ANOVA convention prevalence

#### Convention A: inspect all effects

```{r}
df_conv_a <- df_conv %>%
  filter(a2_multiway==1) %>%
  select(`Paper ID`, starts_with("a"), journal)
```

##### Per research article

```{r}
df_conv_a_article <- df_conv_a %>% 
  group_by(journal, `Paper ID`) %>% 
  summarize(a1_per_article = mean(a1_report_all), .groups = "drop") 

df_prev_a <- df_conv_a_article %>%
  group_by(journal) %>%
  summarize(conA = mean(a1_per_article), 
            countA=n()) %>%
  add_row(summarize(df_conv_a_article,
                    journal = "Overall",
                    conA = mean(a1_per_article),
                    countA=n()),
          .before=1) # add summary row
df_prev_a
```
Results showed about `r round(df_pre_a$conA[1]*100,2)`% research articles reported the results of all (significant) main effects and interaction in the ANOVA.

##### Apply corrections (per ANOVA)

```{r}
# percentage of ANOVAs reporting/inspecting all effects among multi-way ANOVA
# (without averaging per research article)
df_conv_a %>%
  group_by(journal) %>%
  summarize(conA = mean(a1_report_all), count=n()) %>%
  add_row(summarize(df_conv_a,
                    journal = "Overall",
                    conA = mean(a1_report_all),
                    count=n()),
          .before=1) # add summary row
```
On average, 74.31% of the inspected multi-way ANOVAs reported the results of all effects (at least those statistically significant ones). Notably, only a few of the remaining articles reported the effects of only one effect (although they did not report all).  

<br>
Whether any correction method was applied (per ANOVA):
```{r}
df_prev_a_corr <- df_conv_a %>%
  group_by(journal, a3_correction) %>%
  summarize(count = n(), .groups="drop") %>%
  add_row(df_conv_a %>%
            group_by(a3_correction) %>%
            summarize(journal = "Overall", count = n()),
          .before=1)
df_prev_a_corr
```
Result show that no correction method (e.g., omnibus F-test or Bonferroni) was applied in any reviewed multi-way ANOVA.

#### Convention B: post-hoc
```{r}
df_conv_b <- df_conv %>%
  filter(max_No_levels>2,
         b6_main_effect_sig != -1) %>% # only include articles reporting the main effect
  select(`Paper ID`, max_No_levels, starts_with("b"), journal) %>% 
  mutate(isConB = b6_main_effect_sig == b8_posthoc) 
```

##### Per research article
```{r}
# percentage of (not) performing post-hoc analysis when the main effect is (not) significant
df_conv_b_artile <- df_conv_b %>%
  group_by(journal, `Paper ID`) %>%
  summarize(meanB_arti = mean(isConB), # the prevalence coefficient
            count = n(),
            .groups="drop")

# show the result
df_prev_b <- df_conv_b_artile %>%
  group_by(journal) %>%
  summarize(conB = mean(meanB_arti),
            countB= n()) %>%
  add_row(df_conv_b_artile %>%
            summarize(journal = "Overall", 
                      conB = mean(meanB_arti),
                      countB = n()),
          .before=1) # add summary row
df_prev_b
```
Overall, about **`r round(df_prev_b$conB[1]*100,2)`%** research articles performed the post-hoc analysis when the main effect (with three or more levels) was significant *or* did not perform the post-hoc analysis when the main effect was not significant.

##### Apply corrections (per ANOVA)

```{r}
# percentage of ANOVAs performing post-hoc analysis (only) when the main effect is significant
# (or) not perform the post-hoc analysis when the main effect is not significant
df_conv_b %>%
  group_by(journal) %>%
  summarize(conB = mean(isConB),
            count=n()) %>%
  add_row(summarize(df_conv_b,
                    journal = "Overall",
                    conB = mean(isConB),
                    count=n()),
          .before=1) # add summary row
```

Multiple comparison corrections (per ANOVA)
```{r}
df_prev_b_corr <- df_conv_b %>%
  filter(b8_posthoc == 1) %>% # only examine articles performing post-hoc analysis
  group_by(journal, b9_correction) %>%
  summarize(count = n(), .groups="drop") %>%
  add_row(df_conv_b %>%
            filter(b8_posthoc == 1) %>%
            group_by(b9_correction) %>%
            summarize(journal = 'Overall', count = n()),
          .before = 1) %>% 
  pivot_wider(b9_correction, names_from = journal, 
              values_from = count, values_fill = 0)
df_prev_b_corr
```
Notably, this analyses and results included ANOVAs performed post-hoc analysis and apply corrections, but the corresponding main effect was not significant. 

##### Conduct post-hoc analysis and apply corrections with significant main effects
(per ANOVA)
```{r}
df_conv_b %>%
  filter(b8_posthoc == 1) %>% # only examine articles performing post-hoc analysis
  group_by(b6_main_effect_sig, journal, b9_correction) %>%
  summarize(count = n(), .groups="drop") %>%
  add_row(df_conv_b %>%
            filter(b8_posthoc == 1) %>%
            group_by(b6_main_effect_sig, b9_correction) %>%
            summarize(journal = 'Overall', count = n(), .groups="drop"),
          .before =1) %>% 
  pivot_wider(c(b6_main_effect_sig, b9_correction), names_from = journal, 
              values_from = count, values_fill = 0)
```
Results show that most studies performed post-hoc analysis only when the main effect is significant, and most of these studies do not apply any correction procedure. Also, there are some articles in which post-hoc analysis was performed when the main effect is not significant (and no correction procedure was applied).

#### Convention C: simple effect analysis

```{r}
df_conv_c <- df_conv %>%
  filter(N_factor>1,
         c6_inter_sig != -1) %>% # only include ANOVAs reporting the interaction
  select(`Paper ID`, N_factor, starts_with("c") & !starts_with("Con"), journal) %>% 
  mutate(isConC = c6_inter_sig == c8_simple_effect) 
```

##### Per research article 

```{r}
# percentage of (not) performing simple analysis when the interaction is (not) significant
df_conv_c_artile <- df_conv_c %>%
  group_by(journal, `Paper ID`) %>%
  summarize(meanC_art = mean(isConC), # prevalence coefficient
            .groups="drop")

# show the result
df_prev_c <- df_conv_c_artile %>%
  group_by(journal) %>%
  summarize(conC = mean(meanC_art),
            countC = n()) %>%
  add_row(df_conv_c_artile %>%
            summarize(journal = "Overall", 
                      conC = mean(meanC_art),
                      countC = n()),
          .before=1) # add summary row
df_prev_c
```

##### Apply corrections (per ANOVA)

```{r}
# percentage of ANOVAs performing simple effect analysis (only) when the interaction is significant
# (or) not perform the simple effect analysis when the interaction is not significant
df_conv_c %>%
  group_by(journal) %>%
  summarize(conC = mean(isConC),
            count=n()) %>%
  add_row(summarize(df_conv_c,
                    journal = "Overall",
                    conC = mean(isConC),
                    count=n()),
          .before=1) # add summary row
```

Multiple comparison corrections (per ANOVA)
```{r}
df_prev_c_corr <- df_conv_c %>%
  filter(c8_simple_effect == 1) %>%
  group_by(journal, c9_correction) %>%
  summarize(count = n(), .groups="drop") %>%
  add_row(df_conv_c %>%
            filter(c8_simple_effect == 1) %>%  # only include ANOVA performing simple 
            group_by(c9_correction) %>%
            summarize(journal = 'Overall', count = n()),
          .before = 1) %>% 
  pivot_wider(c9_correction, names_from = journal, 
              values_from = count, values_fill = 0)
df_prev_c_corr
```

##### Conduct simple effect analysis and apply corrections with significant interactions
(per ANOVA)
```{r}
df_conv_c %>%
  filter(c8_simple_effect == 1) %>% # only examine articles performing simple effect analysis
  group_by(c6_inter_sig, journal, c9_correction) %>%
  summarize(count = n(), .groups="drop") %>%
  add_row(df_conv_c %>%
            filter(c8_simple_effect == 1) %>%
            group_by(c6_inter_sig, c9_correction) %>%
            summarize(journal = 'Overall', count = n(), .groups="drop"),
          .before =1) %>% 
  pivot_wider(c(c6_inter_sig, c9_correction), names_from = journal, 
              values_from = count, values_fill = 0)
```
Similar to Convention B, most research articles performed simple effect analysis when the interaction is significant, and most of them do not apply any correction procedure. Also, there are some articles performing simple effect analysis when the interaction is not significant (and most of them do not apply any correction procedure).

#### Convention D: separate 

```{r}
df_conv_de <- df_conv %>%
  filter(N_factor>2) %>%
  select(`Paper ID`, N_factor, d1_e1_highest_sig, d1_separate, e1_combine, journal)

# per research article
df_conv_d_artile <- df_conv_de %>%
  filter(d1_e1_highest_sig == 1) %>%
  group_by(`Paper ID`, journal) %>%
  summarize(meanD_art = mean(d1_separate), .groups="drop")

# show the result
df_prev_d <- df_conv_d_artile %>%
  group_by(journal) %>%
  summarize(conD = mean(meanD_art),
            countD = n()) %>%
  add_row(df_conv_d_artile %>%
            summarize(journal = "Overall", 
                      conD = mean(meanD_art),
                      countD = n()),
          .before=1) # add summary row
df_prev_d
```
About half of the articles separated one factors and performed more ANOVAs when the highest-level interaction is significant (although there are not many articles included three or more factors).

#### Convention E: combine 

```{r}
# per research article
df_conv_e_artile <- df_conv_de %>%
  filter(d1_e1_highest_sig == 0) %>%
  group_by(`Paper ID`, journal) %>%
  summarize(meanE_art = mean(e1_combine), .groups="drop")

# show the result
df_prev_e <- df_conv_e_artile %>%
  group_by(journal) %>%
  summarize(conE = mean(meanE_art),
            countE = n()) %>%
  add_row(df_conv_e_artile %>%
  summarize(journal = "Overall", 
            conE = mean(meanE_art),
            countE = n()),
  .before=1) # add summary row
df_prev_e
```
None of the examined research articles combined factors and perform additional ANOVA (explicilty).

#### Summary of convention prevalence

```{r}
df_prev_con <- df_prev_a %>% 
  left_join(df_prev_b, by="journal") %>% 
  left_join(df_prev_c, by="journal") %>% 
  left_join(df_prev_d, by="journal") %>% 
  left_join(df_prev_e, by="journal") %>% 
  mutate(conD = ifelse(is.na(conD), 0, conD),
         countD = ifelse(is.na(countD), 0, countD),
         conE = ifelse(is.na(conE), 0, conE),
         countE = ifelse(is.na(countE), 0, countE)) %>% 
  transmute(Journal = journal,
            `Conv. A` = paste0(round(conA*100,2),"% (", countA, ")"),
            `Conv. B` = paste0(round(conB*100,2),"% (", countB, ")"),
            `Conv. C` = paste0(round(conC*100,2),"% (", countC, ")"),
            `Conv. D` = paste0(round(conD*100,2),"% (", countD, ")"),
            `Conv. E` = paste0(round(conE*100,2),"% (", countE, ")"),
            )

df_prev_con
```

