---
title: "ANOVA conventions may not work as you wish"
author: "[Haiyang Jin](https://haiyangjin.github.io/) and Yuzhu Ji"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output: 
  html_document:
    code_folding: hide
    number_sections: true
    toc: true
    toc_depth: 4
    toc_float: true
    df_print: paged
---

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

# Preparations

```{r setup, include=FALSE}
## load libraries
library(knitr)
library(tidyverse)
library(afex)
library(emmeans)
library(lme4)
library(vcd)
library(papaja)

theme_set(theme_apa())

# set global chunk options, put figures into folder
options(warn=-1, replace.assign=TRUE)
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE, 
  include = TRUE, tidy = FALSE, archive = FALSE,
  size = "big", fig.width=8, fig.asp=0.7, 
  width = 1800,
  emmeans=list(msg.interaction=FALSE))

source(here::here("R", "funcs.R"))
source(here::here("R", "func_kappa.R"))
set.seed(2022)
```

## Read data

```{r}
# # article ID and journal
# df_publ <- readxl::read_excel(here::here("data", "CodingSheet_ANOVA.xlsx"), 
#                               sheet="PaperMeta",
#                               range="A1:M750") %>% 
#   transmute(`Paper ID`, journal = `Publication Title`)
# 
# # "Title_Prescreening" Sheet
# df_prescreen <- readxl::read_excel(here::here("data", "CodingSheet_ANOVA.xlsx"),
#                                    sheet="Title_Prescreening",
#                                    range="A1:C750") %>%
#   left_join(df_publ, by="Paper ID") %>%
#   select(-Title)
#  
# # "ResearchPaper" Sheet
# df_mainscreen <- readxl::read_excel(here::here("data", "CodingSheet_ANOVA.xlsx"), 
#                                sheet="ResearchPaper",
#                                range="A1:L750") %>% 
#   left_join(df_publ, by="Paper ID") %>%
#   select(-Title)
```

```{r}
# article ID and journal
df_publ <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
                              sheet="PaperMeta",
                              range="A1:M13") %>% 
  transmute(`Paper ID`, journal = `Publication Title`)

# "Title_Prescreening" Sheet
df_prescreen <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"),
                                   sheet="Title_Prescreening",
                                   range="A1:C13") %>%
  left_join(df_publ, by="Paper ID") %>%
  select(-Title)

# "ResearchPaper" Sheet
df_mainscreen <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
                               sheet="ResearchPaper",
                               range="A1:L13") %>% 
  left_join(df_publ, by="Paper ID") %>%
  select(-Title)
```

```{r}
# read the coding sheet for the first round by YJ
df_conv_YJ1 <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
                                 sheet="AnalysisInfo_YJ",
                                 range="A1:AO39") %>% 
  select(-Title) 

# read the coding sheet for the first round by HJ
df_conv_HJ1 <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
                                 sheet="AnalysisInfo_HJ",
                                 range="A1:AO39") %>% 
  select(-Title) 
```


```{r}
# # read the coding sheet for the first round (after resolving inconsistency)
# df_conv_1 <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
#                                  sheet="AnalysisInfo_1st",
#                                  range="A1:AO39") %>% 
#   select(-Title) 
# # read the coding sheet for the second round by YJ
# df_conv_YJ2 <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
#                                  sheet="AnalysisInfo_2nd_YJ",
#                                  range="A1:AO39") %>% 
#   select(-Title) 
# # read the coding sheet for the second round by YJ
# df_conv_HJ2 <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
#                                  sheet="AnalysisInfo_2nd_YJ",
#                                  range="A1:AO39") %>% 
#   select(-Title) 
# 
# df_conv <- bind_rows(df_conv_1, df_conv_YJ2, df_conv_HJ2) %>% 
#   left_join(df_publ, by="Paper ID")

df_conv <- readxl::read_excel(here::here("data", "CodingSheet_pilot.xlsx"), 
                                 sheet="AnalysisInfo_HJ",
                                 range="A1:AO39") %>% 
  left_join(df_publ, by="Paper ID") %>% 
  select(-Title) 
```


# Intra-rater consistency
Estimate the intra-rater consistency for the information on whether the study employed ANOVA, experimental designs and the ANOVA prevalence inspected by Y.J. and H.J. separately.

## Research article and ANOVA

```{r}
# # whether it is a research article (unweighted)
# df_res_K <-df_inc_K %>%
#   select(`Research article_YJ`, `Research article_HJ`) %>%
#   group_by(`Research article_YJ`) %>%
#   summarize(count = n(), .groups = "drop") %>%
#   pivot_wider(names_from=`Research article_HJ`, values_from = count, values_fill = 0)
# 
# Ka_res <- df_res_K %>%
#   select(-`Research article_YJ`) %>%
#   as.matrix() %>%
#   Kappa()
# 
# print(Ka_res, CI=TRUE)
```

```{r}
# whether ANOVA was used (unweighted)
df_aov_K <- df_mainscreen %>% 
  select(`Use ANOVA_YJ`, `Use ANOVA_HJ`) %>% 
  group_by(`Use ANOVA_YJ`, `Use ANOVA_HJ`) %>% 
  summarize(count=n(), .groups="drop") %>% 
  pivot_wider(names_from=`Use ANOVA_HJ`, values_from = count, values_fill = 0) 

Ka_aov <- df_aov_K %>% 
  select(-`Use ANOVA_YJ`) %>% 
  as.matrix() %>% 
  Kappa()

print(Ka_aov, CI=TRUE)
```

## The first 120 articles

```{r}
# experimental designs
design_list <- c("N_factor", "max_No_levels")

kappa_0 <- lapply(design_list, thekappa, df1=df_conv_YJ1, df2=df_conv_HJ1, isweighted=TRUE) %>% 
  bind_rows()
```

```{r}
# Convention A
con_a_list <- c("a1_report_all", "a3_correction")

kappa_a <- lapply(con_a_list, thekappa, 
                  df1=filter(df_conv_YJ1, a2_multiway==1), 
                  df2=filter(df_conv_HJ1, a2_multiway==1)) %>% 
  bind_rows()
```

```{r}
# Convention B
con_b_wlist <- c("b1_N_factor3+", "b2_N_significant_b1")
con_b_ulist <- c("b7_posthoc", "b8_correction")

kappa_bw <- lapply(con_b_wlist, thekappa, isweighted=TRUE,
                   df1=filter(df_conv_YJ1, max_No_levels>2), 
                   df2=filter(df_conv_HJ1, max_No_levels>2)) %>% 
  bind_rows()

kappa_bu <- lapply(con_b_ulist, thekappa, 
                   df1=filter(df_conv_YJ1, max_No_levels>2), 
                   df2=filter(df_conv_HJ1, max_No_levels>2)) %>% 
  bind_rows()
kappa_b <- bind_rows(kappa_bw, kappa_bu)
```

```{r}
# Convention C
con_c_wlist <- c("c1_N_2way_inter", "c2_N_sig_in_c1")
con_c_ulist <- c("c7_simple_effect", "c8_correction")

kappa_cw <- lapply(con_c_wlist, thekappa, isweighted=TRUE,
                   df1=filter(df_conv_YJ1, N_factor>1), 
                   df2=filter(df_conv_HJ1, N_factor>1)) %>% 
  bind_rows()

kappa_cu <- lapply(con_c_ulist, thekappa, 
                   df1=filter(df_conv_YJ1, N_factor>1), 
                   df2=filter(df_conv_HJ1, N_factor>1)) %>% 
  bind_rows()
kappa_c <- bind_rows(kappa_cw, kappa_cu)
```

```{r}
# Convention D & E
kappa_d1e1 <- thekappa(df1=filter(df_conv_YJ1, N_factor>2), 
                    df2=filter(df_conv_HJ1, N_factor>2),
                    colname="d1_e1_highest_sig")
# kappa_d <- thekappa(df1=filter(df_conv_YJ1, N_factor>2, d1_e1_highest_sig==1), 
#                     df2=filter(df_conv_HJ1, N_factor>2, d1_e1_highest_sig==1),
#                     colname="d1_separate")
kappa_e <- thekappa(df1=filter(df_conv_YJ1, N_factor>2, d1_e1_highest_sig==0), 
                    df2=filter(df_conv_HJ1, N_factor>2, d1_e1_highest_sig==0),
                    colname="e1_combine")

# kappa_de <- bind_rows(kappa_d1e1, kappa_d, kappa_e)
kappa_de <- bind_rows(kappa_d1e1, kappa_e)
```

```{r}
(kappa_df <- bind_rows(kappa_0, kappa_a, kappa_b, kappa_c, kappa_de))
```

```{r}
# the mean consistency
tibble(mean = mean(kappa_df$value),
       min = min(kappa_df$value),
       max = max(kappa_df$value)) 
```

# ANOVA prevalence

## Screening information

```{r}
df_included_all <- df_mainscreen %>%  
  summarize(journal = "All",
            In1_all = n(),
            In2_after_title = sum(1-Title_Prescreening),
            In3_research = sum(`Research article`),
            In4_ANOVA = sum(`Use ANOVA`),
            In5_included = sum(Included))

# number of articles at different stages
df_included <- df_mainscreen %>% 
  group_by(journal) %>% 
  summarize(In1_all = n(),
            In2_after_title = sum(1-Title_Prescreening),
            In3_research = sum(`Research article`),
            In4_ANOVA = sum(`Use ANOVA`),
            In5_included = sum(Included)) %>% 
  add_row(df_included_all)
df_included
```

```{r}
# number of articles at different stages
df_excluded <- df_mainscreen %>% 
  group_by(journal) %>% 
  summarize(Ex1_all = n(),
            Ex2_after_title = sum(Title_Prescreening),
            Ex3_research = sum(1-`Research article`),
            Ex4_ANOVA = sum(1-`Use ANOVA`),
            Ex5_excluded = sum(1-Included)) %>% 
  add_row( # add summary row
    summarize(df_mainscreen, 
              journal = "All",
              Ex1_all = n(),
              Ex2_after_title = sum(Title_Prescreening),
              Ex3_research = sum(1-`Research article`),
              Ex4_ANOVA = sum(1-`Use ANOVA`),
              Ex5_excluded = sum(1-Included)))
df_excluded
```

## ANOVA prevalence
```{r}
# The percentage of articles employing ANOVA among all research articles:  
df_included_all %>% 
  mutate(prevalence_anova = In4_ANOVA/In3_research)
```

## ANOVA complexity

```{r}
df_complex <- df_conv %>% 
  filter(included==1) %>% 
  transmute(`Paper ID`, N_factor, max_No_levels, Design,
            Design_int = str_split(Design, "_"),
            Avg_No_levels = sapply(Design_int, function(x){mean(as.numeric(x))}),
            Complexity = sapply(Design_int, function(x){prod(as.numeric(x))}),
            journal)
```

Across ANOVAs:
```{r}
df_complex %>% 
  group_by(journal) %>% 
  summarize(mean_N_factor = mean(N_factor),
            mean_max_N_levels = mean(max_No_levels),
            mean_complexity = mean(Complexity)) %>% 
  add_row( # add summary row
    summarize(df_complex, 
              journal = "All",
              mean_N_factor = mean(N_factor),
              mean_max_N_levels = mean(max_No_levels),
              mean_complexity = mean(Complexity))) 
```

```{r}
plot_design <- df_complex %>% 
  mutate(design_ = str_replace_all(Design, '_', '*')) %>% 
  ggplot(aes(x = reorder(design_, Complexity))) +
  geom_histogram(stat="count") +
  labs(x = "Experimental designs")
plot_design
```

alluvial figure (?) [left side is the experimental designs and the right side is the numbers of conditions.]
```{r}
df_complex %>% 
  select(Design, Complexity) %>% 
  group_by(Design, Complexity) %>% 
  summarize(count = n(), .groups="drop") 
```

## ANOVA convention prevalence

### Convention A: inspect all
```{r}
df_conv_a <- df_conv %>% 
  filter(a2_multiway==1) %>% 
  select(`Paper ID`, starts_with("a"), journal)

# percentage of ANOVAs reporting/inspecting all effects among multi-way ANOVA
df_conv_a_all <- summarize(df_conv_a, 
                           journal = "All",
                           conA = mean(a1_report_all))

df_conv_a %>% 
  group_by(journal) %>% 
  summarize(conA = mean(a1_report_all)) %>% 
  add_row(df_conv_a_all) # add summary row
```

```{r}
df_conv_a_adjust <- df_conv_a %>% 
  group_by(a3_correction) %>% 
  summarize(journal = "All", count = n())

df_conv_a %>% 
  group_by(journal, a3_correction) %>% 
  summarize(count = n(), .groups="drop") %>% 
  add_row(df_conv_a_adjust) 
```


### Convention B: post-hoc
```{r}
df_conv_b <- df_conv %>% 
  filter(max_No_levels>2) %>% 
  select(`Paper ID`, max_No_levels, starts_with("b"), journal)

# percentage of (not) performing post-hoc analysis when the main effect is (not) significant
df_conv_b_artile <- df_conv_b %>% 
  mutate(isConB = b5_main_effect_sig == b7_posthoc) %>% 
  group_by(`Paper ID`, journal) %>% 
  summarize(meanB_art = mean(isConB), .groups="drop")

# show the result
df_conv_b_all <- df_conv_b_artile %>% 
  summarize(journal = "All", conB = mean(meanB_art))

df_conv_b_artile %>% 
  group_by(journal) %>% 
  summarize(conB = mean(meanB_art)) %>% 
  add_row(df_conv_b_all) # add summary row
```

Multiple comparison corrections (per ANOVA)
```{r}
df_conv_b_adjust <- df_conv_b %>% 
  filter(b5_main_effect_sig == 1) %>% 
  group_by(b8_correction) %>% 
  summarize(journal = 'All', count = n())
  
df_conv_b %>% 
  filter(b5_main_effect_sig == 1) %>% 
  group_by(journal, b8_correction) %>% 
  summarize(count = n(), .groups="drop") %>% 
  add_row(df_conv_b_adjust) 
```


### Convention C: simple effect analysis
```{r}
df_conv_c <- df_conv %>% 
  filter(N_factor>1) %>% 
  select(`Paper ID`, N_factor, starts_with("c") & !starts_with("Con"), journal)

# percentage of (not) performing simple analysis when the interaction is (not) significant
df_conv_c_artile <- df_conv_c %>% 
  mutate(isConC = c5_inter_sig == c7_simple_effect) %>% 
  group_by(`Paper ID`, journal) %>% 
  summarize(meanC_art = mean(isConC), .groups="drop")

# show the result
df_conv_c_all <- df_conv_c_artile %>% 
  summarize(journal = "All", conC = mean(meanC_art))

df_conv_c_artile %>% 
  group_by(journal) %>% 
  summarize(conC = mean(meanC_art)) %>% 
  add_row(df_conv_c_all) # add summary row
```

Multiple comparison corrections (per ANOVA)
```{r}
df_conv_c_adjust <- df_conv_c %>% 
  filter(c5_inter_sig == 1) %>% 
  group_by(c8_correction) %>% 
  summarize(journal = 'All', count = n())
  
df_conv_c %>% 
  filter(c5_inter_sig == 1) %>% 
  group_by(journal, c8_correction) %>% 
  summarize(count = n(), .groups="drop") %>% 
  add_row(df_conv_c_adjust)
```

### Convention D: separate 

```{r}
df_conv_de <- df_conv %>% 
  filter(N_factor>2) %>% 
  select(`Paper ID`, N_factor, d1_e1_highest_sig, d1_separate, e1_combine, journal)

# 
df_conv_d_artile <- df_conv_de %>% 
  filter(d1_e1_highest_sig == 1) %>% 
  group_by(`Paper ID`, journal) %>% 
  summarize(meanD_art = mean(d1_separate), .groups="drop")

# show the result
df_conv_d_all <- df_conv_d_artile %>% 
  summarize(journal = "All", conD = mean(meanD_art))

df_conv_d_artile %>% 
  group_by(journal) %>% 
  summarize(conD = mean(meanD_art)) %>% 
  add_row(df_conv_d_all) # add summary row
```

### Convention E: combine 

```{r}
# 
df_conv_e_artile <- df_conv_de %>% 
  filter(d1_e1_highest_sig == 0) %>% 
  group_by(`Paper ID`, journal) %>% 
  summarize(meanE_art = mean(e1_combine), .groups="drop")

# show the result
df_conv_e_all <- df_conv_e_artile %>% 
  summarize(journal = "All", conE = mean(meanE_art))

df_conv_e_artile %>% 
  group_by(journal) %>% 
  summarize(conE = mean(meanE_art)) %>% 
  add_row(df_conv_e_all) # add summary row
```


# Simulating Type I error in ANOVA

```{r}
Nsim <- 10000 # number of simulation
alphas <- c(0.001, 0.005, 0.01, 0.05, (1:4)/10)  # 0.001 ~ 0.4

```

## ANOVA omnibus F-test

```{r}
p_omni <- sim_omnibus(N_subj = 30, iter = Nsim, n_core=16, 
                      file_cache = here::here("simulation", "p_omni.rds"),
                      N_IV = 2:5)
```


```{r}
dfs_sig_omni <- sig_omnibus(p_omni, 0.05) 

dfs_sig_omni %>% 
  select(-c(N_sig, p.value)) %>% 
  group_by(N_IV, effnames) %>% 
  summarize(TypeI = mean(sig), .groups = "drop") %>% 
  pivot_wider(names_from = effnames, values_from = TypeI)
```

```{r}
dfs_sig_omni %>% 
  select(-c(N_sig, p.value)) %>% 
  group_by(N_IV, effnames) %>% 
  summarize(TypeI_with_omni = mean(sig_with_omni), .groups = "drop") %>% 
  pivot_wider(names_from = effnames, values_from = TypeI_with_omni) 
```


## Main effect and post-hoc analysis
One-way ANOVA with three levels

```{r message=F}
# sim_main_posthoc is available in R/funcs.R
p_main_posthoc <- sim_main_posthoc(N_subj = 30, iter = Nsim, n_core=16, 
                                   file_cache = here::here("simulation", "p_main_posthoc.rds"),
                                   N_con = 4) 
```

```{r}
df_TypeI_posthoc <- sig_main_posthoc(p_main_posthoc, 0.05) %>% 
  mutate(sig_anypost = N_sigpost > 0, # any of the pairwise comparison is significant
         sig_both_main_post = sig_main * sig_anypost) %>% # both the main and any of pairwise are significant
  group_by(alpha, adjust) %>% 
  summarize(TypeI_both = mean(sig_both_main_post), 
            TypeI_postonly = mean(sig_anypost),
            .groups = "drop")

df_TypeI_posthoc
```


Claim significant results only when both the main effect and at least one of the post-hoc tests (with different multiple comparison corrections) are significant:
```{r}
df_TypeI_posthoc %>% 
  filter(adjust != "none") %>% # only when using multiple comparison correction
  select(-TypeI_postonly) 
```

Claim significant results only when the main effect and at least one of the post-hoc tests (without different multiple comparison corrections) are significant:
```{r}
df_TypeI_posthoc %>% 
  filter(adjust == "none") # only when NOT using multiple comparison correction
```

Claim significant results only when at least one of the post-hoc tests (with different multiple comparison corrections) are significant (regardless of the main effect results): 
```{r}
df_TypeI_posthoc %>% 
  filter(adjust != "none") %>% # only when using multiple comparison correction
  select(-TypeI_both)
```


## Interaction and simple effect analysis

```{r}
p_inter_simple <- sim_inter_simple(N_subj = 30, iter = Nsim, n_core=16, 
                                   file_cache = here::here("simulation", "p_inter_simple.rds"))
```

```{r}
p_inter_simple %>% 
  group_by(adjust) %>% 
  summarize(mean(p_mainA<0.05), mean(p_mainB<0.05), mean(p_inter<0.05)) 
```

When both the interaction and at least one of the (four) simple effects were significant:
```{r}
df_TypeI_inter <- sig_inter_simple(p_inter_simple, 0.05) %>% 
  mutate(sig_anysimple4 = N_sigsimple4 > 0,
         sig_anysimple2byA = N_sigsimple2byA > 0,
         sig_anysimple2byB = N_sigsimple2byB > 0,
         sig_both_inter_simple4 = sig_inter * sig_anysimple4,
         sig_both_inter_simple2byA = sig_inter * sig_anysimple2byA,
         sig_both_inter_simple2byB = sig_inter * sig_anysimple2byB) %>% 
  group_by(alpha, adjust) %>% 
  summarize(TypeI_both = mean(sig_both_inter_simple4), 
            TypeI_simpleonly = mean(sig_anysimple4),
            TypeI_bothbyA = mean(sig_both_inter_simple2byA),
            TypeI_bothbyB = mean(sig_both_inter_simple2byB),
            TypeI_simpleonlybyA = mean(sig_anysimple2byA),
            TypeI_simpleonlybyB = mean(sig_anysimple2byB),
            .groups = "drop")

df_TypeI_inter %>% 
  filter(adjust != "none") 
```

```{r}
df_TypeI_inter %>% 
  filter(adjust == "none") 
```



